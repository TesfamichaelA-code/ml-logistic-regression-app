# Logistic Regression ML Pipeline

A complete end-to-end machine learning pipeline using **Logistic Regression** to predict Titanic passenger survival.

## Project Structure

```
ml-logistic-regression-app/
├── README.md                              # Project documentation
├── .gitignore                             # Git ignore file
├── backend/
│   ├── __init__.py                       # Package init
│   ├── main.py                           # FastAPI application
│   ├── schemas.py                        # Pydantic schemas
│   ├── config.py                         # Configuration settings
│   └── requirements.txt                  # Backend dependencies
├── frontend/
│   ├── app.py                            # Streamlit application
│   └── requirements.txt                  # Frontend dependencies
├── model/
│   └── logistic_model.joblib             # Trained model (generated by notebook)
├── notebook/
│   └── logistic_regression_pipeline.ipynb # Complete ML pipeline notebook
└── venv/                                  # Virtual environment (not tracked)
```

## Features

- **Data Loading**: Titanic dataset from public URL
- **Exploratory Data Analysis**: Comprehensive visualizations
- **Data Cleaning**: Missing value handling, feature selection
- **Feature Engineering**: FamilySize, IsAlone, AgeGroup, FarePerPerson
- **sklearn Pipeline**: Preprocessing + Model in a single pipeline
- **Model Training**: Logistic Regression with balanced class weights
- **Evaluation**: Accuracy, Precision, Recall, F1, Confusion Matrix, ROC-AUC
- **Model Export**: Saved as `logistic_model.joblib`

## Quick Start

### Prerequisites

```bash
pip install pandas numpy matplotlib seaborn scikit-learn joblib
```

### Run the Notebook

1. Open `notebook/logistic_regression_pipeline.ipynb`
2. Run all cells top-to-bottom
3. The trained model will be saved to `model/logistic_model.joblib`

### Use the Trained Model

```python
import joblib
import pandas as pd

# Load the model
model = joblib.load('model/logistic_model.joblib')

# Create new passenger data
new_passenger = pd.DataFrame({
    'Pclass': [1],
    'Sex': ['female'],
    'Age': [25],
    'SibSp': [1],
    'Parch': [0],
    'Fare': [100.0],
    'Embarked': ['S'],
    'FamilySize': [2],
    'IsAlone': [0],
    'FarePerPerson': [50.0],
    'AgeGroup': ['YoungAdult']
})

# Make prediction
prediction = model.predict(new_passenger)
probability = model.predict_proba(new_passenger)

print(f"Survival Prediction: {'Survived' if prediction[0] == 1 else 'Did Not Survive'}")
print(f"Probability of Survival: {probability[0][1]*100:.2f}%")
```

## Model Performance

| Metric    | Training | Test |
| --------- | -------- | ---- |
| Accuracy  | ~82%     | ~80% |
| Precision | ~79%     | ~77% |
| Recall    | ~75%     | ~73% |
| F1-Score  | ~77%     | ~75% |
| ROC-AUC   | ~87%     | ~85% |

## Pipeline Architecture

```
Input Data
    │
    ▼
┌─────────────────────────────────────────────┐
│              ColumnTransformer              │
│  ┌─────────────────┬─────────────────────┐  │
│  │   Numerical     │    Categorical      │  │
│  │   Pipeline      │    Pipeline         │  │
│  │  ┌───────────┐  │  ┌───────────────┐  │  │
│  │  │ Imputer   │  │  │ Imputer       │  │  │
│  │  │ (median)  │  │  │ (most_freq)   │  │  │
│  │  └─────┬─────┘  │  └───────┬───────┘  │  │
│  │        ▼        │          ▼          │  │
│  │  ┌───────────┐  │  ┌───────────────┐  │  │
│  │  │ Standard  │  │  │ OneHotEncoder │  │  │
│  │  │ Scaler    │  │  │               │  │  │
│  │  └───────────┘  │  └───────────────┘  │  │
│  └─────────────────┴─────────────────────┘  │
└─────────────────────────────────────────────┘
                     │
                     ▼
         ┌─────────────────────┐
         │ Logistic Regression │
         │  (balanced weights) │
         └─────────────────────┘
                     │
                     ▼
              Predictions
```

## License

MIT License

---

## API Backend

### Setup

```bash
# Navigate to backend directory
cd backend

# Install dependencies (using the project's virtual environment)
source ../venv/bin/activate
pip install -r requirements.txt
```

### Run the API Server

```bash
# From the backend directory
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### API Endpoints

| Method | Endpoint         | Description                 |
| ------ | ---------------- | --------------------------- |
| GET    | `/`              | Health check                |
| GET    | `/health`        | Detailed health status      |
| GET    | `/docs`          | Swagger UI documentation    |
| GET    | `/redoc`         | ReDoc documentation         |
| POST   | `/predict`       | Single passenger prediction |
| POST   | `/predict/batch` | Batch predictions           |
| GET    | `/model/info`    | Model information           |

### Example API Request

```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "pclass": 1,
    "sex": "female",
    "age": 25,
    "sibsp": 1,
    "parch": 0,
    "fare": 100.0,
    "embarked": "S"
  }'
```

### Example Response

```json
{
  "survived": true,
  "survival_probability": 0.8523,
  "confidence": 85.23,
  "message": "Survived"
}
```

---

## Streamlit Frontend

### Setup

```bash
# Navigate to frontend directory
cd frontend

# Install dependencies (using the project's virtual environment)
source ../venv/bin/activate
pip install -r requirements.txt
```

### Run the Streamlit App

```bash
# From the frontend directory
streamlit run app.py
```

Or from the project root:

```bash
source venv/bin/activate
streamlit run frontend/app.py
```

### Features

- Interactive input form for passenger details
- Real-time API health status indicator
- Visual prediction results with probability bar
- Responsive two-column layout
- Detailed instructions in sidebar

### Usage

1. Ensure the FastAPI backend is running on `http://localhost:8000`
2. Start the Streamlit app
3. Fill in passenger details (class, sex, age, etc.)
4. Click **Predict Survival**
5. View the prediction results with survival probability
