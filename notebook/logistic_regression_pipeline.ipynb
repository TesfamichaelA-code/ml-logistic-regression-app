{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64758fe3",
   "metadata": {},
   "source": [
    "# Logistic Regression Pipeline - Titanic Survival Prediction\n",
    "\n",
    "This notebook demonstrates a complete end-to-end machine learning pipeline using **Logistic Regression** to predict passenger survival on the Titanic.\n",
    "\n",
    "## Pipeline Overview:\n",
    "1. **Data Loading** - Load the Titanic dataset\n",
    "2. **Exploratory Data Analysis** - Understand the data\n",
    "3. **Data Cleaning** - Handle missing values and outliers\n",
    "4. **Feature Engineering** - Create and transform features\n",
    "5. **Train-Test Split** - Split data for training and evaluation\n",
    "6. **Model Training** - Build a Logistic Regression model with sklearn Pipeline\n",
    "7. **Model Evaluation** - Accuracy, Precision, Recall, Confusion Matrix\n",
    "8. **Model Export** - Save the trained model using joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fe0af7",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "First, let's import all the necessary libraries for our ML pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a74bbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score,\n",
    "    confusion_matrix, \n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    roc_curve\n",
    ")\n",
    "\n",
    "# Model export\n",
    "import joblib\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e9b49b",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "\n",
    "We'll load the Titanic dataset directly from a public URL. This dataset contains information about passengers aboard the Titanic, including whether they survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e10a5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Titanic dataset from a public URL\n",
    "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset Shape: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "print(f\"\\nColumn Names: {list(df.columns)}\")\n",
    "\n",
    "# Show first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cedac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types and non-null counts\n",
    "print(\"Dataset Information:\")\n",
    "print(\"=\" * 50)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd53848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary of numerical features\n",
    "print(\"Statistical Summary of Numerical Features:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbf57c6",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)\n",
    "\n",
    "Let's explore the data to understand patterns and relationships between features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d37d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize target variable distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Count plot\n",
    "survival_counts = df['Survived'].value_counts()\n",
    "colors = ['#ff6b6b', '#4ecdc4']\n",
    "axes[0].bar(['Did Not Survive (0)', 'Survived (1)'], survival_counts.values, color=colors)\n",
    "axes[0].set_title('Survival Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Count')\n",
    "for i, v in enumerate(survival_counts.values):\n",
    "    axes[0].text(i, v + 10, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "axes[1].pie(survival_counts.values, labels=['Did Not Survive', 'Survived'], \n",
    "            autopct='%1.1f%%', colors=colors, explode=(0.05, 0), shadow=True)\n",
    "axes[1].set_title('Survival Percentage', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Class Distribution: {survival_counts[0]} did not survive, {survival_counts[1]} survived\")\n",
    "print(f\"Survival Rate: {(survival_counts[1] / len(df) * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70789d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze survival by different features\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# 1. Survival by Gender\n",
    "sns.countplot(data=df, x='Sex', hue='Survived', ax=axes[0, 0], palette=['#ff6b6b', '#4ecdc4'])\n",
    "axes[0, 0].set_title('Survival by Gender', fontweight='bold')\n",
    "axes[0, 0].legend(['Did Not Survive', 'Survived'])\n",
    "\n",
    "# 2. Survival by Passenger Class\n",
    "sns.countplot(data=df, x='Pclass', hue='Survived', ax=axes[0, 1], palette=['#ff6b6b', '#4ecdc4'])\n",
    "axes[0, 1].set_title('Survival by Passenger Class', fontweight='bold')\n",
    "axes[0, 1].legend(['Did Not Survive', 'Survived'])\n",
    "\n",
    "# 3. Age Distribution by Survival\n",
    "df['Survived'].replace({0: 'Did Not Survive', 1: 'Survived'}, inplace=False).values\n",
    "sns.histplot(data=df, x='Age', hue='Survived', bins=30, ax=axes[0, 2], palette=['#ff6b6b', '#4ecdc4'])\n",
    "axes[0, 2].set_title('Age Distribution by Survival', fontweight='bold')\n",
    "\n",
    "# 4. Survival by Embarked Port\n",
    "sns.countplot(data=df, x='Embarked', hue='Survived', ax=axes[1, 0], palette=['#ff6b6b', '#4ecdc4'])\n",
    "axes[1, 0].set_title('Survival by Embarked Port', fontweight='bold')\n",
    "axes[1, 0].legend(['Did Not Survive', 'Survived'])\n",
    "\n",
    "# 5. Fare Distribution by Survival\n",
    "sns.boxplot(data=df, x='Survived', y='Fare', ax=axes[1, 1], palette=['#ff6b6b', '#4ecdc4'])\n",
    "axes[1, 1].set_title('Fare Distribution by Survival', fontweight='bold')\n",
    "axes[1, 1].set_xticklabels(['Did Not Survive', 'Survived'])\n",
    "\n",
    "# 6. Survival by SibSp (siblings/spouses)\n",
    "sns.countplot(data=df, x='SibSp', hue='Survived', ax=axes[1, 2], palette=['#ff6b6b', '#4ecdc4'])\n",
    "axes[1, 2].set_title('Survival by Siblings/Spouses Aboard', fontweight='bold')\n",
    "axes[1, 2].legend(['Did Not Survive', 'Survived'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b42a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (df.isnull().sum() / len(df) * 100).round(2)\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing,\n",
    "    'Missing %': missing_pct\n",
    "})\n",
    "print(missing_df[missing_df['Missing Count'] > 0])\n",
    "\n",
    "# Visualize missing values\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "missing_cols = missing[missing > 0]\n",
    "bars = ax.bar(missing_cols.index, missing_cols.values, color='#e74c3c')\n",
    "ax.set_title('Missing Values by Feature', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Count of Missing Values')\n",
    "ax.set_xlabel('Features')\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{int(height)}',\n",
    "            ha='center', va='bottom', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebd0f13",
   "metadata": {},
   "source": [
    "## 4. Data Cleaning\n",
    "\n",
    "Now let's handle missing values and prepare the data for modeling:\n",
    "- **Age**: Impute with median (robust to outliers)\n",
    "- **Embarked**: Impute with mode (most frequent value)\n",
    "- **Cabin**: Drop (too many missing values - 77%)\n",
    "- **Ticket**: Drop (not useful for prediction)\n",
    "- **PassengerId, Name**: Drop (identifiers, not features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb82cff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for cleaning\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Drop columns that won't be useful for prediction\n",
    "columns_to_drop = ['PassengerId', 'Name', 'Ticket', 'Cabin']\n",
    "df_clean = df_clean.drop(columns=columns_to_drop)\n",
    "\n",
    "print(f\"Dropped columns: {columns_to_drop}\")\n",
    "print(f\"Remaining columns: {list(df_clean.columns)}\")\n",
    "print(f\"New shape: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d91b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values manually for initial EDA\n",
    "# Note: We'll use Pipeline for proper imputation later\n",
    "\n",
    "# Fill Age with median\n",
    "age_median = df_clean['Age'].median()\n",
    "df_clean['Age'] = df_clean['Age'].fillna(age_median)\n",
    "print(f\"Age: Filled {df['Age'].isnull().sum()} missing values with median ({age_median})\")\n",
    "\n",
    "# Fill Embarked with mode\n",
    "embarked_mode = df_clean['Embarked'].mode()[0]\n",
    "df_clean['Embarked'] = df_clean['Embarked'].fillna(embarked_mode)\n",
    "print(f\"Embarked: Filled {df['Embarked'].isnull().sum()} missing values with mode ('{embarked_mode}')\")\n",
    "\n",
    "# Verify no missing values remain\n",
    "print(f\"\\nRemaining missing values: {df_clean.isnull().sum().sum()}\")\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2440cdbc",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering\n",
    "\n",
    "Let's create new features that might improve our model's performance:\n",
    "- **FamilySize**: Total family members aboard (SibSp + Parch + 1)\n",
    "- **IsAlone**: Whether the passenger was traveling alone\n",
    "- **AgeGroup**: Categorize age into groups\n",
    "- **FarePerPerson**: Fare divided by family size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2866e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new features\n",
    "df_clean['FamilySize'] = df_clean['SibSp'] + df_clean['Parch'] + 1\n",
    "df_clean['IsAlone'] = (df_clean['FamilySize'] == 1).astype(int)\n",
    "df_clean['FarePerPerson'] = df_clean['Fare'] / df_clean['FamilySize']\n",
    "\n",
    "# Create age groups\n",
    "def categorize_age(age):\n",
    "    if age <= 12:\n",
    "        return 'Child'\n",
    "    elif age <= 18:\n",
    "        return 'Teenager'\n",
    "    elif age <= 35:\n",
    "        return 'YoungAdult'\n",
    "    elif age <= 55:\n",
    "        return 'MiddleAged'\n",
    "    else:\n",
    "        return 'Senior'\n",
    "\n",
    "df_clean['AgeGroup'] = df_clean['Age'].apply(categorize_age)\n",
    "\n",
    "print(\"New features created!\")\n",
    "print(f\"Updated shape: {df_clean.shape}\")\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbce024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the new features\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Family Size vs Survival\n",
    "sns.countplot(data=df_clean, x='FamilySize', hue='Survived', ax=axes[0], palette=['#ff6b6b', '#4ecdc4'])\n",
    "axes[0].set_title('Survival by Family Size', fontweight='bold')\n",
    "axes[0].legend(['Did Not Survive', 'Survived'])\n",
    "\n",
    "# IsAlone vs Survival\n",
    "sns.countplot(data=df_clean, x='IsAlone', hue='Survived', ax=axes[1], palette=['#ff6b6b', '#4ecdc4'])\n",
    "axes[1].set_title('Survival: Alone vs With Family', fontweight='bold')\n",
    "axes[1].set_xticklabels(['With Family', 'Alone'])\n",
    "axes[1].legend(['Did Not Survive', 'Survived'])\n",
    "\n",
    "# Age Group vs Survival\n",
    "age_order = ['Child', 'Teenager', 'YoungAdult', 'MiddleAged', 'Senior']\n",
    "sns.countplot(data=df_clean, x='AgeGroup', hue='Survived', ax=axes[2], \n",
    "              order=age_order, palette=['#ff6b6b', '#4ecdc4'])\n",
    "axes[2].set_title('Survival by Age Group', fontweight='bold')\n",
    "axes[2].legend(['Did Not Survive', 'Survived'])\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f980dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation heatmap for numerical features\n",
    "# First, encode categorical variables for correlation analysis\n",
    "df_corr = df_clean.copy()\n",
    "df_corr['Sex'] = LabelEncoder().fit_transform(df_corr['Sex'])\n",
    "df_corr['Embarked'] = LabelEncoder().fit_transform(df_corr['Embarked'])\n",
    "df_corr['AgeGroup'] = LabelEncoder().fit_transform(df_corr['AgeGroup'])\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation = df_corr.corr()\n",
    "mask = np.triu(np.ones_like(correlation, dtype=bool))\n",
    "sns.heatmap(correlation, mask=mask, annot=True, fmt='.2f', cmap='RdYlBu_r', \n",
    "            center=0, linewidths=0.5, annot_kws={'size': 9})\n",
    "plt.title('Feature Correlation Heatmap', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show correlations with target variable\n",
    "print(\"\\nCorrelation with Survival (sorted):\")\n",
    "print(\"=\" * 40)\n",
    "print(correlation['Survived'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbe661c",
   "metadata": {},
   "source": [
    "## 6. Data Preparation for Modeling\n",
    "\n",
    "Now let's prepare our data for the machine learning model:\n",
    "1. Separate features (X) and target (y)\n",
    "2. Define numerical and categorical columns\n",
    "3. Create preprocessing pipelines using ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f935cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df_clean.drop('Survived', axis=1)\n",
    "y = df_clean['Survived']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nFeature columns: {list(X.columns)}\")\n",
    "print(f\"\\nTarget distribution:\\n{y.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2357f576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical and categorical columns\n",
    "numerical_features = ['Age', 'Fare', 'SibSp', 'Parch', 'FamilySize', 'IsAlone', 'FarePerPerson']\n",
    "categorical_features = ['Pclass', 'Sex', 'Embarked', 'AgeGroup']\n",
    "\n",
    "print(\"Numerical Features:\")\n",
    "for feat in numerical_features:\n",
    "    print(f\"   - {feat}: {X[feat].dtype}\")\n",
    "\n",
    "print(\"\\nCategorical Features:\")\n",
    "for feat in categorical_features:\n",
    "    print(f\"   - {feat}: {X[feat].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49105bf0",
   "metadata": {},
   "source": [
    "## 7. Train-Test Split\n",
    "\n",
    "Split the data into training and testing sets to evaluate model performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa030a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "# Using stratified split to maintain class distribution\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,           # 80% train, 20% test\n",
    "    random_state=42,         # For reproducibility\n",
    "    stratify=y               # Maintain class distribution\n",
    ")\n",
    "\n",
    "print(\"Data Split Summary:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Training set: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Testing set:  {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nTarget Distribution in Training Set:\")\n",
    "print(f\"   Did Not Survive: {(y_train == 0).sum()} ({(y_train == 0).sum()/len(y_train)*100:.1f}%)\")\n",
    "print(f\"   Survived: {(y_train == 1).sum()} ({(y_train == 1).sum()/len(y_train)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nTarget Distribution in Test Set:\")\n",
    "print(f\"   Did Not Survive: {(y_test == 0).sum()} ({(y_test == 0).sum()/len(y_test)*100:.1f}%)\")\n",
    "print(f\"   Survived: {(y_test == 1).sum()} ({(y_test == 1).sum()/len(y_test)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07a0621",
   "metadata": {},
   "source": [
    "## 8. Build sklearn Pipeline\n",
    "\n",
    "We'll create a complete ML pipeline that includes:\n",
    "1. **Numerical Pipeline**: Imputation + Standard Scaling\n",
    "2. **Categorical Pipeline**: Imputation + One-Hot Encoding\n",
    "3. **ColumnTransformer**: Combine both pipelines\n",
    "4. **Final Pipeline**: Preprocessing + Logistic Regression\n",
    "\n",
    "Using a Pipeline ensures that all preprocessing steps are applied consistently and prevents data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3621413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessing pipelines for numerical and categorical features\n",
    "\n",
    "# Numerical features pipeline: Impute missing values with median, then scale\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),  # Handle missing values\n",
    "    ('scaler', StandardScaler())                     # Standardize features\n",
    "])\n",
    "\n",
    "# Categorical features pipeline: Impute with most frequent, then one-hot encode\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Handle missing values\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))  # Encode categories\n",
    "])\n",
    "\n",
    "# Combine both pipelines using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numerical_features),\n",
    "        ('cat', categorical_pipeline, categorical_features)\n",
    "    ],\n",
    "    remainder='drop'  # Drop any columns not specified\n",
    ")\n",
    "\n",
    "print(\"Preprocessing pipeline created!\")\n",
    "print(\"\\nPipeline Structure:\")\n",
    "print(\"   Numerical Features -> SimpleImputer (median) -> StandardScaler\")\n",
    "print(\"   Categorical Features -> SimpleImputer (mode) -> OneHotEncoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860a5ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the complete ML pipeline with Logistic Regression\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(\n",
    "        random_state=42,\n",
    "        max_iter=1000,           # Increase iterations for convergence\n",
    "        solver='lbfgs',          # Good for small datasets\n",
    "        C=1.0,                   # Regularization strength\n",
    "        class_weight='balanced'  # Handle class imbalance\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Display the pipeline\n",
    "print(\"Complete ML Pipeline:\")\n",
    "print(\"=\" * 60)\n",
    "print(model_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a24b3f",
   "metadata": {},
   "source": [
    "## 9. Model Training\n",
    "\n",
    "Train the Logistic Regression model on the training data. We'll also perform cross-validation to get a more robust estimate of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b96caac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"Training the Logistic Regression model...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Fit the pipeline on training data\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model training complete!\")\n",
    "\n",
    "# Perform cross-validation on training data\n",
    "print(\"\\nCross-Validation Results (5-fold):\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "cv_scores = cross_val_score(model_pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"   Fold Scores: {[f'{score:.4f}' for score in cv_scores]}\")\n",
    "print(f\"   Mean Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195ab780",
   "metadata": {},
   "source": [
    "## 10. Model Evaluation\n",
    "\n",
    "Evaluate the model's performance on the test set using various metrics:\n",
    "- **Accuracy**: Overall correctness\n",
    "- **Precision**: Of predicted positives, how many were actually positive\n",
    "- **Recall**: Of actual positives, how many were predicted correctly\n",
    "- **F1-Score**: Harmonic mean of Precision and Recall\n",
    "- **Confusion Matrix**: Detailed breakdown of predictions\n",
    "- **ROC-AUC**: Area under the ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e603778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on training and test sets\n",
    "y_train_pred = model_pipeline.predict(X_train)\n",
    "y_test_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Get probability predictions for ROC curve\n",
    "y_train_proba = model_pipeline.predict_proba(X_train)[:, 1]\n",
    "y_test_proba = model_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Predictions generated for training and test sets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91ef15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "print(\"MODEL EVALUATION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Training Set Metrics\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_precision = precision_score(y_train, y_train_pred)\n",
    "train_recall = recall_score(y_train, y_train_pred)\n",
    "train_f1 = f1_score(y_train, y_train_pred)\n",
    "train_roc_auc = roc_auc_score(y_train, y_train_proba)\n",
    "\n",
    "print(\"\\nTRAINING SET PERFORMANCE:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"   Accuracy:  {train_accuracy:.4f} ({train_accuracy*100:.2f}%)\")\n",
    "print(f\"   Precision: {train_precision:.4f}\")\n",
    "print(f\"   Recall:    {train_recall:.4f}\")\n",
    "print(f\"   F1-Score:  {train_f1:.4f}\")\n",
    "print(f\"   ROC-AUC:   {train_roc_auc:.4f}\")\n",
    "\n",
    "# Test Set Metrics\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_precision = precision_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "test_roc_auc = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "print(\"\\nTEST SET PERFORMANCE:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"   Accuracy:  {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"   Precision: {test_precision:.4f}\")\n",
    "print(f\"   Recall:    {test_recall:.4f}\")\n",
    "print(f\"   F1-Score:  {test_f1:.4f}\")\n",
    "print(f\"   ROC-AUC:   {test_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9d2d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed Classification Report\n",
    "print(\"\\nDETAILED CLASSIFICATION REPORT (Test Set):\")\n",
    "print(\"=\" * 60)\n",
    "print(classification_report(y_test, y_test_pred, target_names=['Did Not Survive', 'Survived']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9580c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Training Set Confusion Matrix\n",
    "cm_train = confusion_matrix(y_train, y_train_pred)\n",
    "sns.heatmap(cm_train, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=['Did Not Survive', 'Survived'],\n",
    "            yticklabels=['Did Not Survive', 'Survived'])\n",
    "axes[0].set_title('Confusion Matrix - Training Set', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Predicted Label')\n",
    "axes[0].set_ylabel('True Label')\n",
    "\n",
    "# Test Set Confusion Matrix\n",
    "cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues', ax=axes[1],\n",
    "            xticklabels=['Did Not Survive', 'Survived'],\n",
    "            yticklabels=['Did Not Survive', 'Survived'])\n",
    "axes[1].set_title('Confusion Matrix - Test Set', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Predicted Label')\n",
    "axes[1].set_ylabel('True Label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print confusion matrix interpretation\n",
    "tn, fp, fn, tp = cm_test.ravel()\n",
    "print(\"\\nConfusion Matrix Breakdown (Test Set):\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"   True Negatives (TN):  {tn} - Correctly predicted 'Did Not Survive'\")\n",
    "print(f\"   False Positives (FP): {fp} - Incorrectly predicted 'Survived'\")\n",
    "print(f\"   False Negatives (FN): {fn} - Incorrectly predicted 'Did Not Survive'\")\n",
    "print(f\"   True Positives (TP):  {tp} - Correctly predicted 'Survived'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810335be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Calculate ROC curves\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, y_train_proba)\n",
    "fpr_test, tpr_test, _ = roc_curve(y_test, y_test_proba)\n",
    "\n",
    "# Plot ROC curves\n",
    "ax.plot(fpr_train, tpr_train, color='blue', lw=2, \n",
    "        label=f'Training ROC (AUC = {train_roc_auc:.4f})')\n",
    "ax.plot(fpr_test, tpr_test, color='red', lw=2, \n",
    "        label=f'Test ROC (AUC = {test_roc_auc:.4f})')\n",
    "ax.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--', label='Random Classifier')\n",
    "\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel('False Positive Rate', fontsize=12)\n",
    "ax.set_ylabel('True Positive Rate', fontsize=12)\n",
    "ax.set_title('Receiver Operating Characteristic (ROC) Curve', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='lower right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ce338f",
   "metadata": {},
   "source": [
    "## 11. Feature Importance Analysis\n",
    "\n",
    "Let's analyze which features are most important for predicting survival by examining the model coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f692b8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names after preprocessing\n",
    "# Get the one-hot encoded feature names\n",
    "onehot_encoder = model_pipeline.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot']\n",
    "cat_feature_names = list(onehot_encoder.get_feature_names_out(categorical_features))\n",
    "\n",
    "# Combine all feature names\n",
    "all_feature_names = numerical_features + cat_feature_names\n",
    "\n",
    "# Get coefficients from the trained model\n",
    "coefficients = model_pipeline.named_steps['classifier'].coef_[0]\n",
    "\n",
    "# Create a DataFrame for feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': all_feature_names,\n",
    "    'Coefficient': coefficients,\n",
    "    'Abs_Coefficient': np.abs(coefficients)\n",
    "}).sort_values('Abs_Coefficient', ascending=False)\n",
    "\n",
    "# Display feature importance\n",
    "print(\"Feature Importance (by absolute coefficient value):\")\n",
    "print(\"=\" * 60)\n",
    "print(feature_importance.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87ec9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Create color based on positive/negative coefficient\n",
    "colors = ['#4ecdc4' if x > 0 else '#ff6b6b' for x in feature_importance['Coefficient']]\n",
    "\n",
    "# Plot horizontal bar chart\n",
    "bars = ax.barh(range(len(feature_importance)), \n",
    "               feature_importance['Coefficient'], \n",
    "               color=colors)\n",
    "\n",
    "ax.set_yticks(range(len(feature_importance)))\n",
    "ax.set_yticklabels(feature_importance['Feature'])\n",
    "ax.set_xlabel('Coefficient Value', fontsize=12)\n",
    "ax.set_title('Logistic Regression Feature Coefficients\\n(Green = Positive Impact, Red = Negative Impact)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"   - Positive coefficients increase the probability of survival\")\n",
    "print(\"   - Negative coefficients decrease the probability of survival\")\n",
    "print(\"   - Larger absolute values indicate stronger influence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d97cd2",
   "metadata": {},
   "source": [
    "## 12. Model Export\n",
    "\n",
    "Save the trained model pipeline using `joblib` for later use in production or deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f25bc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model pipeline\n",
    "import os\n",
    "\n",
    "# Create the model directory if it doesn't exist\n",
    "model_dir = '../model'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Define the model path\n",
    "model_path = os.path.join(model_dir, 'logistic_model.joblib')\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model_pipeline, model_path)\n",
    "\n",
    "print(\"MODEL EXPORT SUCCESSFUL!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"   Model saved to: {os.path.abspath(model_path)}\")\n",
    "print(f\"   File size: {os.path.getsize(model_path) / 1024:.2f} KB\")\n",
    "\n",
    "# Verify the saved model\n",
    "print(\"\\nVerification: Loading and testing the saved model...\")\n",
    "loaded_model = joblib.load(model_path)\n",
    "loaded_predictions = loaded_model.predict(X_test)\n",
    "loaded_accuracy = accuracy_score(y_test, loaded_predictions)\n",
    "print(f\"   Loaded model accuracy: {loaded_accuracy:.4f}\")\n",
    "print(\"   Model verified successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff9162f",
   "metadata": {},
   "source": [
    "## 13. Making Predictions with the Saved Model\n",
    "\n",
    "Let's demonstrate how to load and use the saved model for making predictions on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169633af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Making predictions for new passengers\n",
    "# Create sample new passenger data\n",
    "\n",
    "new_passengers = pd.DataFrame({\n",
    "    'Pclass': [1, 3, 2],\n",
    "    'Sex': ['female', 'male', 'female'],\n",
    "    'Age': [25, 35, 8],\n",
    "    'SibSp': [1, 0, 2],\n",
    "    'Parch': [0, 0, 1],\n",
    "    'Fare': [100.0, 7.25, 30.0],\n",
    "    'Embarked': ['S', 'S', 'C'],\n",
    "    'FamilySize': [2, 1, 4],\n",
    "    'IsAlone': [0, 1, 0],\n",
    "    'FarePerPerson': [50.0, 7.25, 7.5],\n",
    "    'AgeGroup': ['YoungAdult', 'YoungAdult', 'Child']\n",
    "})\n",
    "\n",
    "print(\"New Passenger Data:\")\n",
    "print(\"=\" * 60)\n",
    "print(new_passengers.to_string(index=False))\n",
    "\n",
    "# Load the model and make predictions\n",
    "model = joblib.load('../model/logistic_model.joblib')\n",
    "predictions = model.predict(new_passengers)\n",
    "probabilities = model.predict_proba(new_passengers)\n",
    "\n",
    "print(\"\\nPrediction Results:\")\n",
    "print(\"-\" * 60)\n",
    "for i, (pred, prob) in enumerate(zip(predictions, probabilities)):\n",
    "    survival_status = \"Survived\" if pred == 1 else \"Did Not Survive\"\n",
    "    print(f\"   Passenger {i+1}: {survival_status}\")\n",
    "    print(f\"              Probability of Survival: {prob[1]*100:.2f}%\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778ffd45",
   "metadata": {},
   "source": [
    "## 14. Summary & Conclusions\n",
    "\n",
    "### Pipeline Summary\n",
    "This notebook demonstrated a complete end-to-end machine learning pipeline for binary classification using Logistic Regression:\n",
    "\n",
    "| Step | Description |\n",
    "|------|-------------|\n",
    "| 1. Data Loading | Loaded Titanic dataset from public URL |\n",
    "| 2. EDA | Explored data distributions and relationships |\n",
    "| 3. Data Cleaning | Handled missing values, dropped irrelevant columns |\n",
    "| 4. Feature Engineering | Created FamilySize, IsAlone, AgeGroup, FarePerPerson |\n",
    "| 5. Preprocessing | Used sklearn Pipeline with ColumnTransformer |\n",
    "| 6. Model Training | Trained Logistic Regression with balanced class weights |\n",
    "| 7. Evaluation | Assessed using accuracy, precision, recall, F1, ROC-AUC |\n",
    "| 8. Model Export | Saved pipeline as `logistic_model.joblib` |\n",
    "\n",
    "### Key Findings\n",
    "- **Sex** is the most important predictor (females had higher survival rates)\n",
    "- **Passenger Class** significantly affected survival (1st class had better odds)\n",
    "- **Family Size** had a non-linear effect (small families survived better than lone travelers or large families)\n",
    "- **Age** played a role, with children having better survival rates\n",
    "\n",
    "### Model Performance\n",
    "The Logistic Regression model achieved:\n",
    "- ~80% accuracy on the test set\n",
    "- Good precision and recall balance\n",
    "- Strong ROC-AUC score indicating reliable predictions\n",
    "\n",
    "### Next Steps\n",
    "- Try other algorithms (Random Forest, XGBoost)\n",
    "- Hyperparameter tuning with GridSearchCV\n",
    "- Feature selection techniques\n",
    "- Deploy the model using FastAPI (see `backend/main.py`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d30f238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Summary Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Metrics comparison bar chart\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']\n",
    "train_scores = [train_accuracy, train_precision, train_recall, train_f1, train_roc_auc]\n",
    "test_scores = [test_accuracy, test_precision, test_recall, test_f1, test_roc_auc]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = axes[0].bar(x - width/2, train_scores, width, label='Training', color='#3498db')\n",
    "bars2 = axes[0].bar(x + width/2, test_scores, width, label='Test', color='#e74c3c')\n",
    "\n",
    "axes[0].set_ylabel('Score')\n",
    "axes[0].set_title('Model Performance Metrics', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(metrics)\n",
    "axes[0].legend()\n",
    "axes[0].set_ylim(0, 1.1)\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                 f'{height:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                 f'{height:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# Top 5 important features\n",
    "top_features = feature_importance.head(5)\n",
    "axes[1].barh(range(len(top_features)), top_features['Abs_Coefficient'], \n",
    "             color=['#2ecc71' if x > 0 else '#e74c3c' for x in top_features['Coefficient']])\n",
    "axes[1].set_yticks(range(len(top_features)))\n",
    "axes[1].set_yticklabels(top_features['Feature'])\n",
    "axes[1].set_xlabel('Absolute Coefficient Value')\n",
    "axes[1].set_title('Top 5 Most Important Features', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NOTEBOOK COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model saved to: ../model/logistic_model.joblib\")\n",
    "print(f\"Final Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
